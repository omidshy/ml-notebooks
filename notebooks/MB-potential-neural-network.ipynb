{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/omidshy/ML/blob/master/src/MB-potential.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FMj6evQUH4rQ"
   },
   "source": [
    "# Modeling the Müller-Brown Potential using a Neural Network\n",
    "\n",
    "In this tutorial, we will learn how to use a neural network (NN) model to predict the energy of points on the Müller-Brown potential energy surface.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install plotly\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1y8otrleFRXC"
   },
   "outputs": [],
   "source": [
    "from math import exp, pow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5gEWLszUpQV"
   },
   "source": [
    "## Defining the Müller-Brown Potential\n",
    "\n",
    "Bellow you can see the functional form of the Müller-Brown potential. For more details see [here](https://www.wolframcloud.com/objects/demonstrations/TrajectoriesOnTheMullerBrownPotentialEnergySurface-source.nb).\n",
    "\n",
    "$v(x,y) = \\sum_{k=0}^3 A_k \\mathrm{exp}\\left[ a_k (x - x_k^0)^2 + b_k (x - x_k^0) (y - y_k^0) + c_k (y - y_k^0)^2 \\right] $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the Müller-Brown potential as a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N0JzzAZ1UZdx"
   },
   "outputs": [],
   "source": [
    "def mueller_brown_potential(x, y):\n",
    "  A = [-200, -100, -170, 15]\n",
    "  a = [-1, -1, -6.5, 0.7]\n",
    "  b = [0, 0, 11, 0.6]\n",
    "  c = [-10, -10, -6.5, 0.7]\n",
    "  x0 = [1, 0, -0.5, -1.0]\n",
    "  y0 = [0, 0.5, 1.5, 1]\n",
    "  value = 0\n",
    "  for k in range(0, 4):\n",
    "    # Scale the function by 0.1 to make plotting easier.\n",
    "    value += 0.1 * A[k] * exp( a[k] * pow(x-x0[k], 2.0) + b[k] * (x-x0[k]) * (y-y0[k]) + c[k] * pow(y-y0[k], 2.0))\n",
    "  return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4GfIwnIKU9E-"
   },
   "source": [
    "## Generate Training Data\n",
    "\n",
    "Next, we need to generate data points to train the neural network. The training data will be generated using the Müller-Brown Potential and a range of x and y values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WIEw90Hx9XMr",
    "outputId": "73aa645c-5ed6-47ec-8ea1-b526d2539e03"
   },
   "outputs": [],
   "source": [
    "# Generate a set of x and y values\n",
    "xs = np.arange(-1.8, 1.4, 0.1)\n",
    "ys = np.arange(-0.8, 2.4, 0.1)\n",
    "\n",
    "# Create a rectangular grid out of two given one-dimensional xs and ys arrays\n",
    "X, Y = np.meshgrid(xs, ys)\n",
    "\n",
    "xy, e = [], []\n",
    "xy_truncated, e_truncated = [], []\n",
    "\n",
    "for y in ys:\n",
    "  for x in xs:\n",
    "    xy.append([x,y])\n",
    "    v = mueller_brown_potential(x,y)\n",
    "    e.append(v) # Storing potential energy values in the e array\n",
    "    if v < 20:  # Keeping only low-energy points for training\n",
    "      xy_truncated.append([x,y])\n",
    "      e_truncated.append(v)\n",
    "\n",
    "# Reshape e array so that we can plot our data on a 2D surface that is len(xs) by len(ys)\n",
    "E = np.reshape(e,(len(ys),-1))\n",
    "\n",
    "# Print some statistics\n",
    "print(\"E_min:\", np.amin(E), \"E_max:\", np.amax(E))\n",
    "print(\"Size of dataset:\", len(e))\n",
    "print(\"Size of truncated dataset:\", len(e_truncated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GHmBKzxwVRGf"
   },
   "source": [
    "### Visualizing Data: 3D Surface\n",
    "\n",
    "We will now create a 3D plot of our data. To make the plot more readable, we will exclude the points that have extremely high energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "fj9-VeCjWRPR",
    "outputId": "36501e9d-7c18-41ad-8787-345800f90ad5"
   },
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Surface(z=E, x=X, y=Y, colorscale='rainbow', cmin=-15, cmax=9)])\n",
    "fig.update_traces(contours_z=dict(show=True, project_z=True))\n",
    "fig.update_layout(title='Müeller-Brown PES', width=500, height=500,\n",
    "                  scene = dict(\n",
    "                  zaxis_title=\"E\",\n",
    "                  zaxis = dict(dtick=3, range=[-15, 15]),\n",
    "                  camera_eye = dict(x=-1.2, y=-1.2, z=1.2)\n",
    "                  ))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_BieFeHXuD7"
   },
   "source": [
    "### Visualizing Data: Contour Surface\n",
    "\n",
    "To allow for an easier visualization of the potential energy surface, we can generate a 2D contour surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "id": "me07-Xz19jGO",
    "outputId": "70268012-626e-478e-b545-29ac2ec3f37c"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3,2.5), dpi=150)\n",
    "levels = [-12, -8, -4, 0, 4, 8, 10]\n",
    "ct = plt.contour(X, Y, E, levels, colors='k')\n",
    "plt.clabel(ct, inline=True, fmt='%3.0f', fontsize=8)\n",
    "ct = plt.contourf(X, Y, E, levels, cmap=plt.cm.rainbow, extend='both', vmin=-15, vmax=0)\n",
    "plt.xlabel(\"x\", labelpad=-0.75)\n",
    "plt.ylabel(\"y\", labelpad=2.5)\n",
    "plt.tick_params(axis='both', pad=2,labelsize=8)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.tick_params(labelsize=8)\n",
    "plt.title('Müeller-Brown Contour Surface', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5BkUIk5YK4i"
   },
   "source": [
    "## Loading PyTorch and Training Data\n",
    "\n",
    "After installing and importing pytorch, we will convert our truncated dataset to a tensor data object. Then, randomly select 80% of the data points for training. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LxoMnpPeDlYg",
    "outputId": "0141498d-991e-49b1-b19e-a9ed53b7d2e2"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "\n",
    "# convert the dataset to TensorDataset\n",
    "dataset = TensorDataset(Tensor(xy_truncated), Tensor(e_truncated))\n",
    "# Randomly select 80% of the data points\n",
    "train_indices = torch.randint(0, len(dataset), (int(len(dataset)*0.8),))\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "# Prepare a DataLoader object using the selected training set\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "print(\"Size of training set:\", len(train_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQUmBoB2cT4s"
   },
   "source": [
    "### Defining the Neural Network Class\n",
    "\n",
    "Here we define our neural network as a Python class. A function ($\\it{train\\_loop}$) is used to loop through our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z3Si6tnBFj93"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, n=20):  # n is the number of neurons of the hidden layer(s)\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2,n), # Linear function taking 2 inputs and outputs data for n neurons\n",
    "            nn.Tanh(),      # Non-linear activation function\n",
    "            nn.Linear(n, 1) # Linear function taking data from n neurons and producing one output\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, epoch):\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute model's prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred.squeeze(), y)\n",
    "\n",
    "        # Backpropagation - using the gradients of the loss function to update the weights and biases\n",
    "        optimizer.zero_grad() # Zero out the gradients from the previous iteration\n",
    "        loss.backward()       # Compute the gradients of the loss function\n",
    "        optimizer.step()      # Update the weights and biases using the gradients\n",
    "\n",
    "        if batch % 32 == 0 and epoch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"epoch: {epoch:>4d} loss: {loss:>7.3f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXpLmuWBcbpg"
   },
   "source": [
    "## Training the Model\n",
    "\n",
    "Now we can train the neural network. We will finish our training when the desired number of epochs has been reached. We will also define other hyper-parameters used for the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PGry3oNqGjof",
    "outputId": "45bb5715-7412-4746-b956-2159d34429c5"
   },
   "outputs": [],
   "source": [
    "n_hidden = 40\n",
    "learning_rate = 1e-2\n",
    "epochs = 2000\n",
    "\n",
    "model = NeuralNetwork(n_hidden)\n",
    "loss_fn = nn.functional.mse_loss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loop(train_loader, model, loss_fn, optimizer, epoch)\n",
    "\n",
    "print(\"Done with Training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNfktUgEc17B"
   },
   "source": [
    "## Plotting Reference, Predicted, and Difference Surfaces\n",
    "\n",
    "Finally, we will plot the Müller-Brown potential energy surface using the analytical function (reference), using the predicted values from the neural network (predicted), and we will show the difference between the predicted and reference surfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fudclASTHAaO",
    "outputId": "bfbc79e4-b81d-468a-f436-9d063790c17a"
   },
   "outputs": [],
   "source": [
    "def show_surface(model):\n",
    "\n",
    "  e_pred = model(Tensor(xy))\n",
    "  E_pred = np.reshape(e_pred.detach().numpy(),(len(ys),-1))\n",
    "  Ediff = np.subtract(E_pred, E)\n",
    "\n",
    "  fig = plt.figure(figsize=(3,7.5), dpi=150)\n",
    "\n",
    "\n",
    "  plt.subplot(3, 1, 1)\n",
    "  levels = [-12, -8, -4, 0, 4, 8]\n",
    "  ct = plt.contour(X, Y, E, levels, colors='k')\n",
    "  plt.clabel(ct, inline=True, fmt='%3.0f', fontsize=8)\n",
    "  ct = plt.contourf(X, Y, E, levels, cmap=plt.cm.rainbow, extend='both', vmin=-15, vmax=0)\n",
    "  plt.title(\"(a) Reference\", fontsize=8)\n",
    "  plt.xlabel(\"x\", labelpad=-0.75)\n",
    "  plt.ylabel(\"y\", labelpad=2.5)\n",
    "  plt.tick_params(axis='both', pad=2,labelsize=8)\n",
    "  cbar= plt.colorbar()\n",
    "  cbar.ax.tick_params(labelsize=8)\n",
    "\n",
    "  plt.subplot(3, 1, 2)\n",
    "  ct = plt.contour(X, Y, E_pred, levels, colors='k')\n",
    "  plt.clabel(ct, inline=True, fmt='%3.0f', fontsize=8)\n",
    "  ct = plt.contourf(X, Y, E_pred, levels, cmap=plt.cm.rainbow, extend='both', vmin=-15, vmax=0)\n",
    "  plt.title(\"(b) Predicted\", fontsize=8)\n",
    "  plt.xlabel(\"x\", labelpad=-0.75)\n",
    "  plt.ylabel(\"y\", labelpad=2.5)\n",
    "  plt.tick_params(axis='both', pad=2,labelsize=8)\n",
    "  cbar= plt.colorbar()\n",
    "  cbar.ax.tick_params(labelsize=8)\n",
    "\n",
    "  plt.subplot(3, 1, 3)\n",
    "  levels = [-4, -2, 0, 2, 4]\n",
    "  ct = plt.contour(X, Y, Ediff, levels, colors='k')\n",
    "  plt.clabel(ct, inline=True, fmt='%3.0f', fontsize=8)\n",
    "  ct = plt.contourf(X, Y, Ediff, levels, cmap=plt.cm.rainbow, extend='both', vmin=-4, vmax=4)\n",
    "  plt.title(\"(c) Difference\", fontsize=8)\n",
    "  plt.xlabel(\"x\", labelpad=-0.75)\n",
    "  plt.ylabel(\"y\", labelpad=2.5)\n",
    "  print(\"diff, min, max:\", np.amin(Ediff), np.amax(Ediff))\n",
    "  plt.tick_params(axis='both', pad=2,labelsize=8)\n",
    "  cbar= plt.colorbar()\n",
    "  cbar.ax.tick_params(labelsize=8)\n",
    "\n",
    "  plt.tight_layout()\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "show_surface(model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
